import{_ as a,c as t,a as e,p as n,o}from"./chunks/framework.KTf6nTsp.js";const k=JSON.parse('{"title":"What is Prompt?","description":"","frontmatter":{"title":"What is Prompt?","date":"2023-06-15T00:00:00.000Z","timestampId":"230615a","lastUpdated":"2023-06-15 18:46"},"headers":[],"relativePath":"blog/what-is-prompt.md","filePath":"blog/what-is-prompt.md"}'),p={name:"blog/what-is-prompt.md"},r=e("p",null,"一篇关于「Prompt」的极极极简介绍。",-1),i=e("hr",null,null,-1),l=["id"],c=e("nav",{class:"table-of-contents"},[e("ul")],-1),d=[c],h=n(`<p>「<em>Prompt</em>」是什么？</p><p>由于知识储备的欠缺，这个词的起源我不太能追溯到。但相信在 GPT 时代，大家或多或少都听过这个词。关于「Prompt」，网络上有很多很多的解释：<u>often contains instructions and examples of what you’d like the LLM to do</u><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>、<u>instructions issued to a computer system (such as a text-to-image artificial intelligence) in the form of written or spoken language</u><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>、<u>an instruction or discussion topic a user provides for the ChatGPT AI model to respond to</u><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>……简单概括一下就是：Prompt 是<strong>输入到语言模型中的指示性、引导性信息</strong>。</p><p>很多朋友可能在体验 ChatGPT 的时候可能感觉它并没有别人吹的那么惊艳，觉得它不听话、回答毫无价值，废话连篇、不符合期望。我想这部分朋友可能对它的定位和能力有一点误解。所以我在这里大概介绍一下 ChatGPT 这个玩意。</p><p><em>ChatGPT</em> 是 <a href="https://openai.com" target="_blank" rel="noreferrer">OpenAI</a> 开发的一个聊天机器人程序，它<u>使用基于 GPT-3.5、GPT-4 架构的大语言模型（Large Language Model, LLM）并以强化学习（Reinforcement Learing, RL）训练</u><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。它具有很强的处理<strong>自然语言</strong>的能力，可以真正意义上理解用户输入的文本，并生成一个回答。在一些简单的情况下，它的回答还是相对靠谱的。但是由于我们平时使用的自然语言通常<strong>省略了很多逻辑细节和前提条件</strong>，所以当我们使用人类间交流的日常语言来进行输入时，ChatGPT 生成的答案可能并不总是会符合用户的预期。所以在使用 ChatGPT 以及其他的 LLM 时，给出合理的 Prompt 就十分重要了。</p><p>对比下面两个 Prompt，虽然都不是很具有编写 Prompt 的规范性，但还是高下立判。</p><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>有什么好听的歌曲推荐？</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>你是一名专业的音乐鉴赏师，为一个平常一般听 Mandopop、Cantopop、Contemporary Folk 的年轻男性推荐 5 - 10 首歌曲。</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>可以明显地看出，第二个 Prompt 比第一个提供了更多的信息（音乐类型），并作出了一些限制（歌曲数量），还为 LLM 设定了一个实际的角色。总的来说，第二个 Prompt 可以被认为是一个合格的、有效的 Prompt。</p><p>根据不同的分类方式，Prompt 可以被分成不同的类型。最常见的分类是依据样本的数量将其分为 <em>Zero-Shot Prompt</em> 和 <em>Few-Shot Prompt</em>。前者不向模型提供相关的实例，如</p><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>Translate Flower to Spanish.</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Few-Shot Prompt 则允许模型在少量示例或指导信息的帮助下生成回答，如：</p><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>English: music</span></span>
<span class="line"><span>Spanish: música</span></span>
<span class="line"><span>English: father</span></span>
<span class="line"><span>Spanish: padre</span></span>
<span class="line"><span>English: flower</span></span>
<span class="line"><span>Spanish: {}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>Prompt 的编写相当值得学习。后续的文章中我会进一步介绍其常见的的编写规范与技巧。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>andrew makes things, <a href="https://blog.andrewcantino.com/blog/2021/04/21/prompt-engineering-tips-and-tricks/" target="_blank" rel="noreferrer">Prompt Engineering Tips and Tricks with GPT-3</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>Wikipedia, <a href="https://en.wikipedia.org/wiki/Prompt" target="_blank" rel="noreferrer">Prompt</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Vincent Terrasi, <a href="https://www.searchenginejournal.com/how-to-write-chatgpt-prompts/479324/#close" target="_blank" rel="noreferrer">How To Write ChatGPT Prompts To Get The Best Results</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>Wikipedia, <a href="https://zh.wikipedia.org/wiki/ChatGPT" target="_blank" rel="noreferrer">ChatGPT</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p></li></ol></section>`,15);function m(s,f,u,g,b,P){return o(),t("div",null,[r,i,e("div",{id:s.$frontmatter.timestampId},d,8,l),h])}const v=a(p,[["render",m]]);export{k as __pageData,v as default};
